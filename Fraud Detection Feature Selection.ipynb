{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Time to Datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['TransactionStartTime'] = pd.to_datetime(data1['TransactionStartTime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting features from Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Month,Day,Weekday,Hour,Minute from training\n",
    "data1['Month'] = data1['TransactionStartTime'].dt.month\n",
    "data1['Weekday'] = data1['TransactionStartTime'].dt.weekday\n",
    "data1['Day'] = data1['TransactionStartTime'].dt.day\n",
    "data1['Hour'] = data1['TransactionStartTime'].dt.hour\n",
    "data1['Minute'] = data1['TransactionStartTime'].dt.minute\n",
    "data1['Seconds'] = data1['TransactionStartTime'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['Value','TransactionId','BatchId','AccountId','SubscriptionId','CustomerId','CurrencyCode','CountryCode','TransactionStartTime']\n",
    "data=data1.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get dummies for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting categorical dummies\n",
    "columns= [\"ProviderId\", \"ProductCategory\", \"ProductId\", \"ChannelId\"]\n",
    "data = pd.get_dummies(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Amount column set to credit(0) and Debit(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Amount']=data['Amount'].apply(lambda x: 0 if(x<0) else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoder\n",
    "\n",
    "LabelEncoder converts each class under specified feature to a numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object types into integer types \n",
    "'''le = preprocessing.LabelEncoder()\n",
    "data['TransactionId'] = le.fit_transform(data['TransactionId'])\n",
    "data['BatchId'] = le.fit_transform(data['BatchId'])\n",
    "data['AccountId']  = le.fit_transform(data['AccountId'])\n",
    "data['SubscriptionId']= le.fit_transform( data['SubscriptionId']) \n",
    "data['CustomerId']= le.fit_transform( data['CustomerId'])\n",
    "data['CurrencyCode']= le.fit_transform( data['CurrencyCode'])\n",
    "data['ProviderId']= le.fit_transform( data['ProviderId'])\n",
    "data['ProductCategory']= le.fit_transform( data['ProductCategory'])\n",
    "data['ProductId']= le.fit_transform( data['ProductId'])\n",
    "data['ChannelId']= le.fit_transform( data['ChannelId'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Dataset ### \n",
    "\n",
    "Here we'll use **Synthetic Oversampling:** This method helps to avoid overfitting. In this method, a small subset of minority is chosen and synthetic examples of this subset are created to balance up the overall dataset. This adds new information to the dataset and increases the overall number of observations.\n",
    "We use ***SMOTE*** (synthetic minority oversampling technique) to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=data.drop(['FraudResult'], axis=1)\n",
    "y1=data[['FraudResult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_algo=SMOTE(random_state=0)\n",
    "smote_data_X,smote_data_Y=smote_algo.fit_sample(X_train,y_train)\n",
    "smote_data_X=pd.DataFrame(data=smote_data_X, columns=X_train.columns)\n",
    "smote_data_Y=pd.DataFrame(data=smote_data_Y,columns=['FraudResult'])\n",
    "\n",
    "#Join X and Y smote data into one\n",
    "smote_data=smote_data_X\n",
    "smote_data['FraudResult']=smote_data_Y['FraudResult']\n",
    "\n",
    "#Count of fraud and non-fraud cases on smote after resampling\n",
    "print(\"Fraud: {}\".format((smote_data[\"FraudResult\"]==1).sum()))\n",
    "print(\"Non-Fraud: {}\".format((smote_data[\"FraudResult\"]==0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Fraud and Non-Fraud Transactions\n",
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(smote_data.FraudResult, palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
    "g.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=smote_data.drop(['FraudResult'], axis=1)\n",
    "y=smote_data[['FraudResult']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.01,solver='lbfgs').fit(X_train, y_train)\n",
    "LR_predict = LR.predict(X_test)\n",
    "\n",
    "print('The Logistic Regression F1-score score is {}'.format(f1_score(y_test,LR_predict,average='weighted')))\n",
    "print('The Logistic Regression Accuracy score is {}'.format(accuracy_score(y_test,LR_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clas = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "forest_clas.fit(X_train, y_train)\n",
    "\n",
    "RF_predict = forest_clas.predict(X_test)\n",
    "\n",
    "print('The  RFC F1-score score is {}'.format(f1_score(y_test,RF_predict,average='weighted')))\n",
    "print('The  RFC Accuracy score is {}'.format(accuracy_score(y_test,RF_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(X_train, y_train)\n",
    "svm_predictions = svm_reg.predict(X_test)\n",
    "\n",
    "print('The  SVR F1-score score is {}'.format(f1_score(y_test,svm_predictions,average='weighted')))\n",
    "print('The  SVR Accuracy score is {}'.format(accuracy_score(y_test,svm_predictions)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = 8\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "for n in range(1,Ks):\n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    KNN_predict=neigh.predict(X_test)\n",
    "    \n",
    "    print('The  KNN F1-score score is {}'.format(f1_score(y_test,KNN_predict,average='weighted')))\n",
    "    print('The  KNN Accuracy score is {}'.format(accuracy_score(y_test,KNN_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''X= preprocessing.StandardScaler().fit(X).transform(X)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the normalization\n",
    "'''from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy before Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cv = KFold(n_splits=10, random_state=0, shuffle=False)\n",
    "classifier_pipeline = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=10))\n",
    "y_pred = cross_val_predict(classifier_pipeline, X, y, cv=cv)\n",
    "print(\"RMSE: \" + str(round(sqrt(mean_squared_error(y,y_pred)),2)))\n",
    "print(\"R_squared: \" + str(round(r2_score(y,y_pred),2)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature selection techniques.\n",
    "\n",
    "1. Univariate Selection\n",
    "\n",
    "2. Feature Importance\n",
    "\n",
    "3. Correlation Matrix with Heatmap\n",
    "\n",
    "4. Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection\n",
    "\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "\n",
    "The example below uses the chi-squared (chi²) statistical test for non-negative features to select 10 of the best features from the Mobile Price Range Prediction Dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Columns','Score']  #naming the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featureScores.nlargest(20,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "You can get the feature importance of each feature of your dataset by using the feature importance property of the model.\n",
    "\n",
    "Feature importance gives you a score for each feature of your data, the higher the score more important or relevant is the feature towards your output variable.\n",
    "\n",
    "Feature importance is an inbuilt class that comes with Tree Based Classifiers, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix with Heatmap\n",
    "\n",
    "Correlation states how the features are related to each other or the target variable.\n",
    "\n",
    "Correlation can be positive (increase in one value of feature increases the value of the target variable) or negative (increase in one value of feature decreases the value of the target variable)\n",
    "\n",
    "Heatmap makes it easy to identify which features are most related to the target variable, we will plot heatmap of correlated features using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs(data.corr()[\"FraudResult\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filter Features by Variance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features=['']\n",
    "X=smote_data(columns = best_features)\n",
    "y=smote_data[['FraudResult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy after Selection\n",
    "LR = LogisticRegression(C=0.01,solver='lbfgs').fit(X_train, y_train)\n",
    "LR_predict = LR.predict(X_test)\n",
    "\n",
    "print('The Logistic Regression F1-score score is {}'.format(f1_score(y_test,LR_predict,average='weighted')))\n",
    "print('The Logistic Regression Accuracy score is {}'.format(accuracy_score(y_test,LR_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
